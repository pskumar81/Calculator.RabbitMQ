name: Performance Tests

on:
  push:
    branches: [ "master" ]
  pull_request:
    branches: [ "master" ]
  schedule:
    # Run performance tests weekly on Sundays at 3 AM UTC
    - cron: '0 3 * * 0'
  workflow_dispatch:

jobs:
  performance-test:
    runs-on: ubuntu-latest
    timeout-minutes: 15  # Prevent infinite runs
    
    services:
      rabbitmq:
        image: rabbitmq:3.13-management
        ports:
          - 5672:5672
          - 15672:15672
        env:
          RABBITMQ_DEFAULT_USER: guest
          RABBITMQ_DEFAULT_PASS: guest
        options: >-
          --health-cmd "rabbitmq-diagnostics -q ping"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 5

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: 9.0.x

    - name: Restore dependencies
      run: dotnet restore

    - name: Build
      run: dotnet build --configuration Release --no-restore

    - name: Start Calculator Server
      run: |
        echo "Starting Calculator Server..."
        cd Calculator.Server
        timeout 300 dotnet run --configuration Release &
        SERVER_PID=$!
        echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV
        echo "Waiting for server to start..."
        sleep 15  # Give server more time to start and connect to RabbitMQ
        
        # Check if server is still running
        if ! kill -0 $SERVER_PID 2>/dev/null; then
          echo "❌ Server failed to start"
          exit 1
        fi
        echo "✅ Server started successfully with PID: $SERVER_PID"

    - name: Create Performance Test Program
      run: |
        mkdir -p PerformanceTest
        cat << 'EOF' > PerformanceTest/PerformanceTest.csproj
        <Project Sdk="Microsoft.NET.Sdk">
          <PropertyGroup>
            <OutputType>Exe</OutputType>
            <TargetFramework>net9.0</TargetFramework>
            <ImplicitUsings>enable</ImplicitUsings>
            <Nullable>enable</Nullable>
          </PropertyGroup>
          <ItemGroup>
            <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="9.0.10" />
            <PackageReference Include="Microsoft.Extensions.Hosting" Version="9.0.10" />
            <PackageReference Include="RabbitMQ.Client" Version="6.8.1" />
            <PackageReference Include="System.Text.Json" Version="9.0.0" />
          </ItemGroup>
          <ItemGroup>
            <ProjectReference Include="../Calculator.Client/Calculator.Client.csproj" />
          </ItemGroup>
        </Project>
        EOF

        cat << 'EOF' > PerformanceTest/Program.cs
        using Calculator.Client.Extensions;
        using Calculator.Client.Services.Interfaces;
        using Microsoft.Extensions.DependencyInjection;
        using Microsoft.Extensions.Hosting;
        using Microsoft.Extensions.Logging;
        using System.Diagnostics;
        
        Console.WriteLine("Starting Calculator Performance Test...");
        
        var host = Host.CreateDefaultBuilder()
            .ConfigureServices((context, services) =>
            {
                services.AddCalculatorClientServices(context.Configuration);
                services.AddLogging(builder => builder.SetMinimumLevel(LogLevel.Warning));
            })
            .Build();
        
        const int iterations = 100; // Reduced for CI environment
        const int concurrentClients = 5; // Reduced for CI environment
        
        Console.WriteLine($"Performance test: {iterations} operations with {concurrentClients} concurrent clients");
        
        try
        {
            var stopwatch = Stopwatch.StartNew();
            var tasks = new List<Task>();
            
            for (int client = 0; client < concurrentClients; client++)
            {
                tasks.Add(Task.Run(async () =>
                {
                    using var clientService = host.Services.GetRequiredService<ICalculatorClientService>();
                    var random = new Random(client); // Different seed per client
                    
                    for (int i = 0; i < iterations / concurrentClients; i++)
                    {
                        try
                        {
                            var num1 = random.NextDouble() * 100; // Smaller numbers for faster processing
                            var num2 = random.NextDouble() * 100;
                            
                            switch (i % 4)
                            {
                                case 0:
                                    await clientService.AddAsync(num1, num2);
                                    break;
                                case 1:
                                    await clientService.SubtractAsync(num1, num2);
                                    break;
                                case 2:
                                    await clientService.MultiplyAsync(num1, num2);
                                    break;
                                case 3:
                                    if (num2 > 0.1) // Avoid division by very small numbers
                                        await clientService.DivideAsync(num1, num2);
                                    break;
                            }
                        }
                        catch (Exception ex)
                        {
                            Console.WriteLine($"Error in operation {i}: {ex.Message}");
                        }
                    }
                }));
            }
            
            await Task.WhenAll(tasks);
            stopwatch.Stop();
            
            var totalTime = stopwatch.ElapsedMilliseconds;
            var throughput = (double)iterations / totalTime * 1000; // operations per second
            
            Console.WriteLine($"Performance Test Results:");
            Console.WriteLine($"Total time: {totalTime}ms");
            Console.WriteLine($"Average time per operation: {(double)totalTime / iterations:F2}ms");
            Console.WriteLine($"Throughput: {throughput:F2} operations/second");
            
            // Performance thresholds (relaxed for CI environment)
            const double maxAvgTimeMs = 200; // 200ms max average per operation
            const double minThroughput = 5; // 5 operations/second minimum
            
            if (totalTime / iterations > maxAvgTimeMs)
            {
                Console.WriteLine($"❌ Performance test FAILED: Average time {(double)totalTime / iterations:F2}ms exceeds threshold {maxAvgTimeMs}ms");
                Environment.Exit(1);
            }
            
            if (throughput < minThroughput)
            {
                Console.WriteLine($"❌ Performance test FAILED: Throughput {throughput:F2} ops/sec below threshold {minThroughput} ops/sec");
                Environment.Exit(1);
            }
            
            Console.WriteLine("✅ Performance test PASSED");
        }
        catch (Exception ex)
        {
            Console.WriteLine($"❌ Performance test FAILED with exception: {ex.Message}");
            Environment.Exit(1);
        }
        finally
        {
            await host.StopAsync();
            host.Dispose();
        }
        EOF

    - name: Run Performance Tests
      run: |
        cd PerformanceTest
        dotnet restore
        dotnet run --configuration Release
        
    - name: Cleanup
      if: always()
      run: |
        if [ ! -z "$SERVER_PID" ]; then
          kill $SERVER_PID || true
        fi

    - name: Upload Performance Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-results
        path: |
          performance-*.log
          performance-*.json